{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPeSUIoUbkTZDyrAu0TIVj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra974/AIMLOPS_IISC/blob/main/NMT_TRANSFORMERS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcBLBDrOw_35",
        "outputId": "9d2322ca-e99a-4da0-cfee-2de1cf057c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DATASETS/ENG_DEU_DATA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH5dpmIYxXjQ",
        "outputId": "7db87c70-e809-4659-8bbc-4ef6458532bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycld2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8F6nrVRxqNk",
        "outputId": "2741bad8-ea43-4c6b-bba9-cd9ce6cfa0b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (0.41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pycld2 as cld2\n",
        "import spacy\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import regex as re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "EQfg9rSIx4rn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!python -m spacy download de_core_news_sm\n",
        "gernlp = spacy.load('de_core_news_sm')\n",
        "engnlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdECDNilyFMe",
        "outputId": "08c015a3-c685-4e5c-e9db-2f6a7867b28c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-23 16:09:46.285578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting de-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removestop(text,stopwords):\n",
        "  raw = text.split()\n",
        "  words = [word for word in raw if not word in stopwords]\n",
        "  cleanwords = ' '.join(words)\n",
        "  return cleanwords\n",
        "\n",
        "def tolower(text):\n",
        "  return text.lower()\n",
        "\n",
        "def removespecial(text):\n",
        "  te1 = re.sub(\"\\s+\",\" \",text)\n",
        "  te2 = re.sub('\\n', '', te1)\n",
        "  te3 = re.sub('\\r', '', te2)\n",
        "  te4 = re.sub(\"[0-9]\",\"\",te3)\n",
        "  te5 = re.sub(\"()@%^&*-_,/\\{}[?|$|.|!]\",\"\",te4)\n",
        "  te6 = re.sub(r\"[\\p{Cc}\\p{Cs}]+\",\"\",te5)\n",
        "  te7 = re.sub(r'[^\\w\\s]','', te6)\n",
        "  te8 = re.sub(\"[^a-zA-Z ]\",\"\",te7)\n",
        "  return te7\n",
        "\n",
        "def removeurl(text):\n",
        "  return re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    pattern = re.compile(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\")\n",
        "    text = re.sub(pattern,' ',text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "oIVXM3EIyp2r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basefolder =  \"/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/\"\n",
        "# germanfiles = [\"commoncrawl_de_en.txt\",\"europarl-v7_de_en.txt\",\"news-commentary-v9_de_en.txt\"]\n",
        "# engfiles = [\"commoncrawl_en_de.txt\",\"europarl-v7_en_de.txt\",\"news-commentary-v9_en_de.txt\"]\n",
        "germanfiles = [\"news-commentary-v9_de_en.txt\"]\n",
        "engfiles = [\"news-commentary-v9_en_de.txt\"]"
      ],
      "metadata": {
        "id": "l0kOP-4ZyV4w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files(fileloc, language):\n",
        "  with open(fileloc,\"rb\") as f:\n",
        "    f_lines = f.readlines()\n",
        "  df = pd.DataFrame(f_lines)\n",
        "  dfc = df.set_axis([language],axis=1)\n",
        "  dfc[language] = dfc[language].str.decode(\"utf-8\")\n",
        "  return dfc"
      ],
      "metadata": {
        "id": "k5IkrZZHyvf2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend=pd.DataFrame()\n",
        "for efile in range(len(germanfiles)):\n",
        "  germanfilepath = basefolder+germanfiles[efile]\n",
        "  print(germanfilepath)\n",
        "  germandff = read_files(germanfilepath,\"german\")\n",
        "  engfilepath = basefolder+engfiles[efile]\n",
        "  engdff = read_files(engfilepath,\"english\")\n",
        "  print(germandff.shape)\n",
        "  print(engdff.shape)\n",
        "  dfconcat = pd.concat([germandff, engdff],axis=\"columns\")\n",
        "  dfappend=pd.concat([dfappend, dfconcat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1jGuFJMyzR8",
        "outputId": "24dbaf38-90da-42fd-97db-07318f6a3e2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/news-commentary-v9_de_en.txt\n",
            "(201288, 1)\n",
            "(201288, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBH2yb4QzZGs",
        "outputId": "03a9ece5-801b-471d-943c-0e115fcc8c1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "german     0\n",
              "english    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxiAyjkzcR5",
        "outputId": "6cd49a52-574a-4776-c6b5-b31748288223"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "430"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "dfappend.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9j3y8mzkgi",
        "outputId": "8f573725-8e3c-48e9-ce5e-1ff8d3d64b4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200858, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "german_stop_words = stopwords.words('german')\n",
        "english_stop_words = stopwords.words('english')\n",
        "\n",
        "dfappend['english_clean'] = dfappend['english'].apply(lambda x: removestop(x,english_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german'].apply(lambda x: removestop(x,german_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german_clean'].apply(lambda x: removespecial(x))\n",
        "dfappend['english_clean'] = dfappend['english_clean'].apply(lambda x: removespecial(x))"
      ],
      "metadata": {
        "id": "GurWsMN50fwG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def langdet(x):\n",
        "  isReliable, textBytesFound, details = cld2.detect(x)\n",
        "  return(details[0][1])"
      ],
      "metadata": {
        "id": "KYehwk6C7IgV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend['is_eng'] = dfappend['english_clean'].apply(lambda x: langdet(x))\n",
        "dfappend['is_ger'] = dfappend['german_clean'].apply(lambda x: langdet(x))"
      ],
      "metadata": {
        "id": "PQF2cq057NJ2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_ger\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "53KC07Ov72E5",
        "outputId": "e5c6cf09-b96f-41a0-9b94-16e6f3a71505"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de     195236\n",
              "un       4267\n",
              "en        861\n",
              "nl         83\n",
              "lb         83\n",
              "ru         83\n",
              "nn         37\n",
              "da         35\n",
              "no         16\n",
              "na         13\n",
              "fy         12\n",
              "af         11\n",
              "la          7\n",
              "sv          7\n",
              "id          7\n",
              "pt          6\n",
              "ms          6\n",
              "fr          5\n",
              "tk          5\n",
              "war         5\n",
              "ie          5\n",
              "ro          5\n",
              "rm          5\n",
              "sk          4\n",
              "fi          4\n",
              "tr          3\n",
              "it          3\n",
              "pl          3\n",
              "eu          3\n",
              "es          3\n",
              "vo          3\n",
              "gv          2\n",
              "cs          2\n",
              "et          2\n",
              "tn          2\n",
              "ha          2\n",
              "lt          2\n",
              "gn          2\n",
              "hr          2\n",
              "rw          2\n",
              "ia          1\n",
              "mfe         1\n",
              "mt          1\n",
              "bi          1\n",
              "tl          1\n",
              "lv          1\n",
              "zzp         1\n",
              "ca          1\n",
              "az          1\n",
              "sco         1\n",
              "fo          1\n",
              "jw          1\n",
              "ts          1\n",
              "aa          1\n",
              "Name: is_ger, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_eng\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "6i9NdCLV8Pw6",
        "outputId": "367973ea-7ead-443f-97fa-1e9f2f55ae94"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en     196526\n",
              "un       4140\n",
              "sco        26\n",
              "ru         24\n",
              "da         20\n",
              "zh         17\n",
              "ca         10\n",
              "ms          7\n",
              "la          7\n",
              "id          5\n",
              "tr          5\n",
              "oc          5\n",
              "rw          5\n",
              "rm          4\n",
              "gn          3\n",
              "pt          3\n",
              "gv          3\n",
              "zzp         3\n",
              "es          3\n",
              "de          2\n",
              "co          2\n",
              "fr          2\n",
              "pl          2\n",
              "ro          2\n",
              "bs          2\n",
              "mfe         2\n",
              "nn          2\n",
              "uz          2\n",
              "ie          2\n",
              "ha          2\n",
              "hmn         1\n",
              "az          1\n",
              "lt          1\n",
              "mg          1\n",
              "af          1\n",
              "vo          1\n",
              "gl          1\n",
              "no          1\n",
              "fj          1\n",
              "sq          1\n",
              "sn          1\n",
              "ts          1\n",
              "sr          1\n",
              "ceb         1\n",
              "kha         1\n",
              "hu          1\n",
              "ga          1\n",
              "bi          1\n",
              "war         1\n",
              "tk          1\n",
              "Name: is_eng, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean = dfappend[(dfappend.is_eng == 'en') & (dfappend.is_ger =='de')]"
      ],
      "metadata": {
        "id": "nJM6MikS8amA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoGg225d8kea",
        "outputId": "d8eee430-4f0f-4b8a-bc36-f7ecb56842b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192441, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappendclean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fPzF_1Qv8qSq",
        "outputId": "c89c5847-2a2b-4902-d164-41476ee2a363"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   german  \\\n",
              "1       SAN FRANCISCO – Es war noch nie leicht, ein ra...   \n",
              "2       In letzter Zeit allerdings ist dies schwierige...   \n",
              "3       Erst letzten Dezember verfassten meine Kollege...   \n",
              "4                     Und es kam, wie es kommen musste.\\n   \n",
              "5       Seit der Veröffentlichung ihrer Artikel ist de...   \n",
              "...                                                   ...   \n",
              "201283  Das bleibt eine der größten Errungenschaften i...   \n",
              "201284  Gleichzeitig scheint sich Zumas revolutionäre ...   \n",
              "201285  In einer Region, wo die älteren Menschen sehr ...   \n",
              "201286  Drei von zehn Südafrikanern sind jünger als 15...   \n",
              "201287  Irgendwie muss Zuma einen Weg finden, einersei...   \n",
              "\n",
              "                                                  english  \\\n",
              "1       SAN FRANCISCO – It has never been easy to have...   \n",
              "2       Lately, with gold prices up more than 300% ove...   \n",
              "3       Just last December, fellow economists Martin F...   \n",
              "4                                 Wouldn’t you know it?\\n   \n",
              "5       Since their articles appeared, the price of go...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one of the greatest ...   \n",
              "201284  At the same time, Zuma’s revolutionary generat...   \n",
              "201285  In a region that reveres the elderly, Zuma’s a...   \n",
              "201286  Three in ten South Africans are younger than 1...   \n",
              "201287  Somehow Zuma must find a way to honor his own ...   \n",
              "\n",
              "                                            english_clean  \\\n",
              "1       SAN FRANCISCO  It never easy rational conversa...   \n",
              "2             Lately gold prices  last decade harder ever   \n",
              "3       Just last December fellow economists Martin Fe...   \n",
              "4                                         Wouldnt know it   \n",
              "5       Since articles appeared price gold moved still...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one greatest recent ...   \n",
              "201284  At time Zumas revolutionary generation still s...   \n",
              "201285  In region reveres elderly Zumas attachment rur...   \n",
              "201286  Three ten South Africans younger  meaning live...   \n",
              "201287  Somehow Zuma must find way honor generations c...   \n",
              "\n",
              "                                             german_clean is_eng is_ger  \n",
              "1       SAN FRANCISCO  Es nie leicht rationales Gesprä...     en     de  \n",
              "2       In letzter Zeit allerdings schwieriger je Gold...     en     de  \n",
              "3       Erst letzten Dezember verfassten Kollegen Mart...     en     de  \n",
              "4                                   Und kam kommen musste     en     de  \n",
              "5       Seit Veröffentlichung Artikel Goldpreis gestiegen     en     de  \n",
              "...                                                   ...    ...    ...  \n",
              "201283  Das bleibt größten Errungenschaften jüngeren G...     en     de  \n",
              "201284  Gleichzeitig scheint Zumas revolutionäre Gener...     en     de  \n",
              "201285  In Region älteren Menschen verehrt werden Zuma...     en     de  \n",
              "201286  Drei zehn Südafrikanern jünger  bedeutet Tag A...     en     de  \n",
              "201287  Irgendwie Zuma Weg finden einerseits Engagemen...     en     de  \n",
              "\n",
              "[192441 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e451e38-6c3d-4589-b7d6-14736815b3b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>german</th>\n",
              "      <th>english</th>\n",
              "      <th>english_clean</th>\n",
              "      <th>german_clean</th>\n",
              "      <th>is_eng</th>\n",
              "      <th>is_ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAN FRANCISCO – Es war noch nie leicht, ein ra...</td>\n",
              "      <td>SAN FRANCISCO – It has never been easy to have...</td>\n",
              "      <td>SAN FRANCISCO  It never easy rational conversa...</td>\n",
              "      <td>SAN FRANCISCO  Es nie leicht rationales Gesprä...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In letzter Zeit allerdings ist dies schwierige...</td>\n",
              "      <td>Lately, with gold prices up more than 300% ove...</td>\n",
              "      <td>Lately gold prices  last decade harder ever</td>\n",
              "      <td>In letzter Zeit allerdings schwieriger je Gold...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Erst letzten Dezember verfassten meine Kollege...</td>\n",
              "      <td>Just last December, fellow economists Martin F...</td>\n",
              "      <td>Just last December fellow economists Martin Fe...</td>\n",
              "      <td>Erst letzten Dezember verfassten Kollegen Mart...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Und es kam, wie es kommen musste.\\n</td>\n",
              "      <td>Wouldn’t you know it?\\n</td>\n",
              "      <td>Wouldnt know it</td>\n",
              "      <td>Und kam kommen musste</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Seit der Veröffentlichung ihrer Artikel ist de...</td>\n",
              "      <td>Since their articles appeared, the price of go...</td>\n",
              "      <td>Since articles appeared price gold moved still...</td>\n",
              "      <td>Seit Veröffentlichung Artikel Goldpreis gestiegen</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201283</th>\n",
              "      <td>Das bleibt eine der größten Errungenschaften i...</td>\n",
              "      <td>Their achievement remains one of the greatest ...</td>\n",
              "      <td>Their achievement remains one greatest recent ...</td>\n",
              "      <td>Das bleibt größten Errungenschaften jüngeren G...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201284</th>\n",
              "      <td>Gleichzeitig scheint sich Zumas revolutionäre ...</td>\n",
              "      <td>At the same time, Zuma’s revolutionary generat...</td>\n",
              "      <td>At time Zumas revolutionary generation still s...</td>\n",
              "      <td>Gleichzeitig scheint Zumas revolutionäre Gener...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201285</th>\n",
              "      <td>In einer Region, wo die älteren Menschen sehr ...</td>\n",
              "      <td>In a region that reveres the elderly, Zuma’s a...</td>\n",
              "      <td>In region reveres elderly Zumas attachment rur...</td>\n",
              "      <td>In Region älteren Menschen verehrt werden Zuma...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201286</th>\n",
              "      <td>Drei von zehn Südafrikanern sind jünger als 15...</td>\n",
              "      <td>Three in ten South Africans are younger than 1...</td>\n",
              "      <td>Three ten South Africans younger  meaning live...</td>\n",
              "      <td>Drei zehn Südafrikanern jünger  bedeutet Tag A...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201287</th>\n",
              "      <td>Irgendwie muss Zuma einen Weg finden, einersei...</td>\n",
              "      <td>Somehow Zuma must find a way to honor his own ...</td>\n",
              "      <td>Somehow Zuma must find way honor generations c...</td>\n",
              "      <td>Irgendwie Zuma Weg finden einerseits Engagemen...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192441 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e451e38-6c3d-4589-b7d6-14736815b3b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e451e38-6c3d-4589-b7d6-14736815b3b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e451e38-6c3d-4589-b7d6-14736815b3b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7bdf5381-8c09-4577-a6b6-f88c80423e77\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7bdf5381-8c09-4577-a6b6-f88c80423e77')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7bdf5381-8c09-4577-a6b6-f88c80423e77 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_07c2ccb6-3220-438d-b85e-985eb78fefc4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dfappendclean')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_07c2ccb6-3220-438d-b85e-985eb78fefc4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dfappendclean');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snjjFtCc9-QW",
        "outputId": "85450f5b-ef4c-4e2f-af61-4bbc4811de57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b3f513c107bd>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=10000\n",
        "dfappendclean = dfappendclean.sample(n=14000)\n",
        "dfappendclean_val = dfappendclean[10000:]\n",
        "dfappendclean = dfappendclean[0:100000]"
      ],
      "metadata": {
        "id": "jV5eOKElDTdC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_list =  dfappendclean['english_clean'].astype(str).tolist()\n",
        "ge_list =  dfappendclean['german_clean'].astype(str).tolist()\n",
        "en_list_val =  dfappendclean_val['english_clean'].astype(str).tolist()\n",
        "ge_list_val =  dfappendclean_val['german_clean'].astype(str).tolist()\n"
      ],
      "metadata": {
        "id": "h1DnFiSKDbVx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(en_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9TfAz0cIEGMj",
        "outputId": "2b3a7739-4c35-486f-ff6f-6f49344bf5f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Past experience Austria shown positive examples',\n",
              " 'Twentytwo percent said hope Ismael Haniyeh Hamass designated prime minister end chaos Palestinian towns provide internal security rule law',\n",
              " 'We better targeting external assistance capacity building programs ready use trade economic muscle necessary demanding counterterrorism clauses bilateral treaties',\n",
              " 'Alternatively moderate exportdownturn scenario real exports falling  fourquarter period real GDP growth could slip  stall speed threshold  leaving US economy vulnerable recessionary relapse',\n",
              " 'And thatraises another question trust']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(ge_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "YSw7rMxREM7Y",
        "outputId": "bf8c46da-3aa9-4fc5-a31f-602aaa11399a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['In Vergangenheit Österreich kaum positive Erfahrungen gemacht worden',\n",
              " 'Zweiundzwanzig Prozent sagten hoffen Ismail Hanija designierte Premierminister Hamas Chaos palästinensischen Städten beenden innere Sicherheit sowie Rechtsstaatlichkeit einführen werde',\n",
              " 'Wir bemühen zielgerichteter Unterstützung außen Programme Ausbau unserer Kapazitäten bereit erforderlichenfalls Handels Wirtschaftsstärke einzusetzen durchzusetzen Antiterrorbestimmungen bilaterale Verträge Aufnahme finden',\n",
              " 'Im Falle AlternativSzenarios leichten Exportabschwung wobei realen Exporte Zeitraum vier Quartalen  Prozent sinken reale BIPWachstum kritische ProzentSchwelle fallen  amerikanische Wirtschaft anfällig einennbsp Rückfall Rezession machen',\n",
              " 'Damit erhebt nächste Frage Wem vertrauen']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en_tokenizer = Tokenizer();\n",
        "en_tokenizer.fit_on_texts(dfappendclean[\"english_clean\"])\n"
      ],
      "metadata": {
        "id": "KPhqYJzf_7_q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ge_tokenizer = Tokenizer();\n",
        "ge_tokenizer.fit_on_texts(dfappendclean[\"german_clean\"])"
      ],
      "metadata": {
        "id": "Kg31udoEJc5Q"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en = en_tokenizer.texts_to_sequences(en_list)     # Output is ragged.\n",
        "en = tf.keras.utils.pad_sequences(en, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge = ge_tokenizer.texts_to_sequences(ge_list)\n",
        "ge = tf.keras.utils.pad_sequences(ge, maxlen=MAX_TOKENS+1, padding='post')\n",
        "\n",
        "en_val = en_tokenizer.texts_to_sequences(en_list_val)     # Output is ragged.\n",
        "en_val = tf.keras.utils.pad_sequences(en_val, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge_val = ge_tokenizer.texts_to_sequences(ge_list_val)\n",
        "ge_val = tf.keras.utils.pad_sequences(ge_val, maxlen=MAX_TOKENS+1, padding='post')\n"
      ],
      "metadata": {
        "id": "q7WmtCIFGtMD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((en, ge))\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((en_val, ge_val))"
      ],
      "metadata": {
        "id": "Gl2vCnjq21ZX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "def prepare_batch(en, ge):\n",
        "\n",
        "    ge_inputs = ge[:, :-1]  # Drop the [END] tokens\n",
        "    ge_labels = ge[:, 1:]   # Drop the [START] tokens\n",
        "\n",
        "    return (en, ge_inputs), ge_labels\n",
        "\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "# Create training and validation set batches.\n",
        "dataset_batches = make_batches(dataset)\n",
        "dataset_batches_val = make_batches(dataset_val)"
      ],
      "metadata": {
        "id": "kPCJcclNXNnd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (pt, en), en_labels in dataset_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49kSPXd5tQS",
        "outputId": "8b7a22b8-89f9-4f19-9cde-0e9da6cc3255"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "zl-TIYFgr9V1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Zb5EHRCIsQH9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "qdNlxpTmsX9j"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "UlwRgvGH9Rws"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "laK9VsbR9bhG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ABwjtYoE9fUs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "YcK04HCb9jFK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2AugLcw09kna"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ],
      "metadata": {
        "id": "Bd7fjkrE9qSK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ],
      "metadata": {
        "id": "YUxJrAa29vZA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "metadata": {
        "id": "wjC6tbE09y-m"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Io4e9uNd93mO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "7TXwHV0M97YX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_size = len(en_tokenizer.word_index)+1;\n",
        "ge_vocab_size = len(ge_tokenizer.word_index)+1;\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size = en_vocab_size,\n",
        "    target_vocab_size = ge_vocab_size,\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "7dx2CYlLDGSB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "fcaLfs1qPxBI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "ANc7y6QmP18L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "jFZama36QOd2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "1ruovAGOQSwT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"NMT_ENG_GER-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "U2_jt308Rz48"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(dataset_batches, epochs=20, validation_data=dataset_batches_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp4g1AOxQUHA",
        "outputId": "f800ab5d-04c2-4829-e61f-3f43aaf72da9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "219/219 [==============================] - 1255s 6s/step - loss: 10.2961 - masked_accuracy: 0.0019 - val_loss: 9.9168 - val_masked_accuracy: 0.0044\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 1221s 6s/step - loss: 9.5471 - masked_accuracy: 0.0043 - val_loss: 9.1781 - val_masked_accuracy: 0.0041\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 1238s 6s/step - loss: 9.1802 - masked_accuracy: 0.0045 - val_loss: 9.0935 - val_masked_accuracy: 0.0051\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 1275s 6s/step - loss: 9.0971 - masked_accuracy: 0.0060 - val_loss: 8.9015 - val_masked_accuracy: 0.0082\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 1241s 6s/step - loss: 8.8686 - masked_accuracy: 0.0120 - val_loss: 8.5621 - val_masked_accuracy: 0.0186\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 1248s 6s/step - loss: 8.5210 - masked_accuracy: 0.0233 - val_loss: 8.0825 - val_masked_accuracy: 0.0354\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 1239s 6s/step - loss: 8.0826 - masked_accuracy: 0.0413 - val_loss: 7.5539 - val_masked_accuracy: 0.0582\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 1241s 6s/step - loss: 7.5830 - masked_accuracy: 0.0672 - val_loss: 6.8703 - val_masked_accuracy: 0.1185\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 1239s 6s/step - loss: 7.0175 - masked_accuracy: 0.1022 - val_loss: 6.1453 - val_masked_accuracy: 0.1737\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 1233s 6s/step - loss: 6.4037 - masked_accuracy: 0.1456 - val_loss: 5.3812 - val_masked_accuracy: 0.2398\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 1242s 6s/step - loss: 5.7386 - masked_accuracy: 0.2053 - val_loss: 4.5571 - val_masked_accuracy: 0.3681\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 1247s 6s/step - loss: 5.0549 - masked_accuracy: 0.2725 - val_loss: 3.7271 - val_masked_accuracy: 0.4506\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 1248s 6s/step - loss: 4.3733 - masked_accuracy: 0.3451 - val_loss: 2.9643 - val_masked_accuracy: 0.5472\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 1267s 6s/step - loss: 3.7227 - masked_accuracy: 0.4150 - val_loss: 2.2973 - val_masked_accuracy: 0.6227\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 1255s 6s/step - loss: 3.1338 - masked_accuracy: 0.4787 - val_loss: 1.7174 - val_masked_accuracy: 0.7139\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 1246s 6s/step - loss: 2.5956 - masked_accuracy: 0.5429 - val_loss: 1.2689 - val_masked_accuracy: 0.7765\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 1255s 6s/step - loss: 2.1489 - masked_accuracy: 0.6017 - val_loss: 0.8900 - val_masked_accuracy: 0.8353\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 1248s 6s/step - loss: 1.7630 - masked_accuracy: 0.6586 - val_loss: 0.6692 - val_masked_accuracy: 0.8675\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 1242s 6s/step - loss: 1.4587 - masked_accuracy: 0.7063 - val_loss: 0.4682 - val_masked_accuracy: 0.9073\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 1249s 6s/step - loss: 1.1640 - masked_accuracy: 0.7580 - val_loss: 0.3368 - val_masked_accuracy: 0.9284\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d036ad7b0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"nmt_en_ge_model_1.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "90ryPhUFHzs4",
        "outputId": "d493acad-0365-4a21-c530-5c1ffae90b9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-90e819e27084>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nmt_en_ge_model_1.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"
          ]
        }
      ]
    }
  ]
}