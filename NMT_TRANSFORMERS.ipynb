{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNBVHX7IPi4Q5rR2dwF7Wlh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra974/AIMLOPS_IISC/blob/main/NMT_TRANSFORMERS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcBLBDrOw_35",
        "outputId": "df535386-4bc0-4167-d0d7-57a64f2d06d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DATASETS/ENG_DEU_DATA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH5dpmIYxXjQ",
        "outputId": "b5c6f7b0-d03b-4f08-9e6b-f0a91e1b2914"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycld2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8F6nrVRxqNk",
        "outputId": "750f8207-0118-4c36-9eec-72176223e626"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (0.41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pycld2 as cld2\n",
        "import spacy\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import regex as re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "EQfg9rSIx4rn"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!python -m spacy download de_core_news_sm\n",
        "gernlp = spacy.load('de_core_news_sm')\n",
        "engnlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdECDNilyFMe",
        "outputId": "2de9d701-0ab2-4a7a-f2eb-792ad2d7241d"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 06:13:12.931490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting de-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removestop(text,stopwords):\n",
        "  raw = text.split()\n",
        "  words = [word for word in raw if not word in stopwords]\n",
        "  cleanwords = ' '.join(words)\n",
        "  return cleanwords\n",
        "\n",
        "def tolower(text):\n",
        "  return text.lower()\n",
        "\n",
        "def removespecial(text):\n",
        "  te1 = re.sub(\"\\s+\",\" \",text)\n",
        "  te2 = re.sub('\\n', '', te1)\n",
        "  te3 = re.sub('\\r', '', te2)\n",
        "  te4 = re.sub(\"[0-9]\",\"\",te3)\n",
        "  te5 = re.sub(\"()@%^&*-_,/\\{}[?|$|.|!]\",\"\",te4)\n",
        "  te6 = re.sub(r\"[\\p{Cc}\\p{Cs}]+\",\"\",te5)\n",
        "  te7 = re.sub(r'[^\\w\\s]','', te6)\n",
        "  te8 = re.sub(\"[^a-zA-Z ]\",\"\",te7)\n",
        "  return te7\n",
        "\n",
        "def removeurl(text):\n",
        "  return re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    pattern = re.compile(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\")\n",
        "    text = re.sub(pattern,' ',text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "oIVXM3EIyp2r"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basefolder =  \"/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/\"\n",
        "# germanfiles = [\"commoncrawl_de_en.txt\",\"europarl-v7_de_en.txt\",\"news-commentary-v9_de_en.txt\"]\n",
        "# engfiles = [\"commoncrawl_en_de.txt\",\"europarl-v7_en_de.txt\",\"news-commentary-v9_en_de.txt\"]\n",
        "germanfiles = [\"news-commentary-v9_de_en.txt\"]\n",
        "engfiles = [\"news-commentary-v9_en_de.txt\"]"
      ],
      "metadata": {
        "id": "l0kOP-4ZyV4w"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files(fileloc, language):\n",
        "  with open(fileloc,\"rb\") as f:\n",
        "    f_lines = f.readlines()\n",
        "  df = pd.DataFrame(f_lines)\n",
        "  dfc = df.set_axis([language],axis=1)\n",
        "  dfc[language] = dfc[language].str.decode(\"utf-8\")\n",
        "  return dfc"
      ],
      "metadata": {
        "id": "k5IkrZZHyvf2"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend=pd.DataFrame()\n",
        "for efile in range(len(germanfiles)):\n",
        "  germanfilepath = basefolder+germanfiles[efile]\n",
        "  print(germanfilepath)\n",
        "  germandff = read_files(germanfilepath,\"german\")\n",
        "  engfilepath = basefolder+engfiles[efile]\n",
        "  engdff = read_files(engfilepath,\"english\")\n",
        "  print(germandff.shape)\n",
        "  print(engdff.shape)\n",
        "  dfconcat = pd.concat([germandff, engdff],axis=\"columns\")\n",
        "  dfappend=pd.concat([dfappend, dfconcat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1jGuFJMyzR8",
        "outputId": "d1e6bef3-7e63-426b-9b60-627d20df144c"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/news-commentary-v9_de_en.txt\n",
            "(201288, 1)\n",
            "(201288, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBH2yb4QzZGs",
        "outputId": "c0a8ca03-e6b6-44d8-c2b0-7319ef24dfab"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "german     0\n",
              "english    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxiAyjkzcR5",
        "outputId": "d5be4f95-13a3-457a-ebf7-09cdc72ee3c8"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "430"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "dfappend.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9j3y8mzkgi",
        "outputId": "9865e6a2-987e-4faa-ba7c-3883de5f150e"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200858, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "german_stop_words = stopwords.words('german')\n",
        "english_stop_words = stopwords.words('english')\n",
        "\n",
        "dfappend['english_clean'] = dfappend['english'].apply(lambda x: removestop(x,english_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german'].apply(lambda x: removestop(x,german_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german_clean'].apply(lambda x: removespecial(x))\n",
        "dfappend['english_clean'] = dfappend['english_clean'].apply(lambda x: removespecial(x))"
      ],
      "metadata": {
        "id": "GurWsMN50fwG"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def langdet(x):\n",
        "  isReliable, textBytesFound, details = cld2.detect(x)\n",
        "  return(details[0][1])"
      ],
      "metadata": {
        "id": "KYehwk6C7IgV"
      },
      "execution_count": 306,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend['is_eng'] = dfappend['english_clean'].apply(lambda x: langdet(x))\n",
        "dfappend['is_ger'] = dfappend['german_clean'].apply(lambda x: langdet(x))"
      ],
      "metadata": {
        "id": "PQF2cq057NJ2"
      },
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_ger\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "53KC07Ov72E5",
        "outputId": "6c2e7df3-1967-41af-a842-87942fd90244"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de     195236\n",
              "un       4267\n",
              "en        861\n",
              "nl         83\n",
              "lb         83\n",
              "ru         83\n",
              "nn         37\n",
              "da         35\n",
              "no         16\n",
              "na         13\n",
              "fy         12\n",
              "af         11\n",
              "la          7\n",
              "sv          7\n",
              "id          7\n",
              "pt          6\n",
              "ms          6\n",
              "fr          5\n",
              "tk          5\n",
              "war         5\n",
              "ie          5\n",
              "ro          5\n",
              "rm          5\n",
              "sk          4\n",
              "fi          4\n",
              "tr          3\n",
              "it          3\n",
              "pl          3\n",
              "eu          3\n",
              "es          3\n",
              "vo          3\n",
              "gv          2\n",
              "cs          2\n",
              "et          2\n",
              "tn          2\n",
              "ha          2\n",
              "lt          2\n",
              "gn          2\n",
              "hr          2\n",
              "rw          2\n",
              "ia          1\n",
              "mfe         1\n",
              "mt          1\n",
              "bi          1\n",
              "tl          1\n",
              "lv          1\n",
              "zzp         1\n",
              "ca          1\n",
              "az          1\n",
              "sco         1\n",
              "fo          1\n",
              "jw          1\n",
              "ts          1\n",
              "aa          1\n",
              "Name: is_ger, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_eng\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "6i9NdCLV8Pw6",
        "outputId": "dc345752-13e8-45d0-c712-4d4671e21046"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en     196526\n",
              "un       4140\n",
              "sco        26\n",
              "ru         24\n",
              "da         20\n",
              "zh         17\n",
              "ca         10\n",
              "ms          7\n",
              "la          7\n",
              "id          5\n",
              "tr          5\n",
              "oc          5\n",
              "rw          5\n",
              "rm          4\n",
              "gn          3\n",
              "pt          3\n",
              "gv          3\n",
              "zzp         3\n",
              "es          3\n",
              "de          2\n",
              "co          2\n",
              "fr          2\n",
              "pl          2\n",
              "ro          2\n",
              "bs          2\n",
              "mfe         2\n",
              "nn          2\n",
              "uz          2\n",
              "ie          2\n",
              "ha          2\n",
              "hmn         1\n",
              "az          1\n",
              "lt          1\n",
              "mg          1\n",
              "af          1\n",
              "vo          1\n",
              "gl          1\n",
              "no          1\n",
              "fj          1\n",
              "sq          1\n",
              "sn          1\n",
              "ts          1\n",
              "sr          1\n",
              "ceb         1\n",
              "kha         1\n",
              "hu          1\n",
              "ga          1\n",
              "bi          1\n",
              "war         1\n",
              "tk          1\n",
              "Name: is_eng, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean = dfappend[(dfappend.is_eng == 'en') & (dfappend.is_ger =='de')]"
      ],
      "metadata": {
        "id": "nJM6MikS8amA"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoGg225d8kea",
        "outputId": "3c867bfd-2159-430d-b455-1c3e1e20c243"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192441, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappendclean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fPzF_1Qv8qSq",
        "outputId": "ee6830a8-8ade-492b-97a7-af156f62fed0"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   german  \\\n",
              "1       SAN FRANCISCO – Es war noch nie leicht, ein ra...   \n",
              "2       In letzter Zeit allerdings ist dies schwierige...   \n",
              "3       Erst letzten Dezember verfassten meine Kollege...   \n",
              "4                     Und es kam, wie es kommen musste.\\n   \n",
              "5       Seit der Veröffentlichung ihrer Artikel ist de...   \n",
              "...                                                   ...   \n",
              "201283  Das bleibt eine der größten Errungenschaften i...   \n",
              "201284  Gleichzeitig scheint sich Zumas revolutionäre ...   \n",
              "201285  In einer Region, wo die älteren Menschen sehr ...   \n",
              "201286  Drei von zehn Südafrikanern sind jünger als 15...   \n",
              "201287  Irgendwie muss Zuma einen Weg finden, einersei...   \n",
              "\n",
              "                                                  english  \\\n",
              "1       SAN FRANCISCO – It has never been easy to have...   \n",
              "2       Lately, with gold prices up more than 300% ove...   \n",
              "3       Just last December, fellow economists Martin F...   \n",
              "4                                 Wouldn’t you know it?\\n   \n",
              "5       Since their articles appeared, the price of go...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one of the greatest ...   \n",
              "201284  At the same time, Zuma’s revolutionary generat...   \n",
              "201285  In a region that reveres the elderly, Zuma’s a...   \n",
              "201286  Three in ten South Africans are younger than 1...   \n",
              "201287  Somehow Zuma must find a way to honor his own ...   \n",
              "\n",
              "                                            english_clean  \\\n",
              "1       SAN FRANCISCO  It never easy rational conversa...   \n",
              "2             Lately gold prices  last decade harder ever   \n",
              "3       Just last December fellow economists Martin Fe...   \n",
              "4                                         Wouldnt know it   \n",
              "5       Since articles appeared price gold moved still...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one greatest recent ...   \n",
              "201284  At time Zumas revolutionary generation still s...   \n",
              "201285  In region reveres elderly Zumas attachment rur...   \n",
              "201286  Three ten South Africans younger  meaning live...   \n",
              "201287  Somehow Zuma must find way honor generations c...   \n",
              "\n",
              "                                             german_clean is_eng is_ger  \n",
              "1       SAN FRANCISCO  Es nie leicht rationales Gesprä...     en     de  \n",
              "2       In letzter Zeit allerdings schwieriger je Gold...     en     de  \n",
              "3       Erst letzten Dezember verfassten Kollegen Mart...     en     de  \n",
              "4                                   Und kam kommen musste     en     de  \n",
              "5       Seit Veröffentlichung Artikel Goldpreis gestiegen     en     de  \n",
              "...                                                   ...    ...    ...  \n",
              "201283  Das bleibt größten Errungenschaften jüngeren G...     en     de  \n",
              "201284  Gleichzeitig scheint Zumas revolutionäre Gener...     en     de  \n",
              "201285  In Region älteren Menschen verehrt werden Zuma...     en     de  \n",
              "201286  Drei zehn Südafrikanern jünger  bedeutet Tag A...     en     de  \n",
              "201287  Irgendwie Zuma Weg finden einerseits Engagemen...     en     de  \n",
              "\n",
              "[192441 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e275b26-49b8-4964-9b17-d123b8203010\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>german</th>\n",
              "      <th>english</th>\n",
              "      <th>english_clean</th>\n",
              "      <th>german_clean</th>\n",
              "      <th>is_eng</th>\n",
              "      <th>is_ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAN FRANCISCO – Es war noch nie leicht, ein ra...</td>\n",
              "      <td>SAN FRANCISCO – It has never been easy to have...</td>\n",
              "      <td>SAN FRANCISCO  It never easy rational conversa...</td>\n",
              "      <td>SAN FRANCISCO  Es nie leicht rationales Gesprä...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In letzter Zeit allerdings ist dies schwierige...</td>\n",
              "      <td>Lately, with gold prices up more than 300% ove...</td>\n",
              "      <td>Lately gold prices  last decade harder ever</td>\n",
              "      <td>In letzter Zeit allerdings schwieriger je Gold...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Erst letzten Dezember verfassten meine Kollege...</td>\n",
              "      <td>Just last December, fellow economists Martin F...</td>\n",
              "      <td>Just last December fellow economists Martin Fe...</td>\n",
              "      <td>Erst letzten Dezember verfassten Kollegen Mart...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Und es kam, wie es kommen musste.\\n</td>\n",
              "      <td>Wouldn’t you know it?\\n</td>\n",
              "      <td>Wouldnt know it</td>\n",
              "      <td>Und kam kommen musste</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Seit der Veröffentlichung ihrer Artikel ist de...</td>\n",
              "      <td>Since their articles appeared, the price of go...</td>\n",
              "      <td>Since articles appeared price gold moved still...</td>\n",
              "      <td>Seit Veröffentlichung Artikel Goldpreis gestiegen</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201283</th>\n",
              "      <td>Das bleibt eine der größten Errungenschaften i...</td>\n",
              "      <td>Their achievement remains one of the greatest ...</td>\n",
              "      <td>Their achievement remains one greatest recent ...</td>\n",
              "      <td>Das bleibt größten Errungenschaften jüngeren G...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201284</th>\n",
              "      <td>Gleichzeitig scheint sich Zumas revolutionäre ...</td>\n",
              "      <td>At the same time, Zuma’s revolutionary generat...</td>\n",
              "      <td>At time Zumas revolutionary generation still s...</td>\n",
              "      <td>Gleichzeitig scheint Zumas revolutionäre Gener...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201285</th>\n",
              "      <td>In einer Region, wo die älteren Menschen sehr ...</td>\n",
              "      <td>In a region that reveres the elderly, Zuma’s a...</td>\n",
              "      <td>In region reveres elderly Zumas attachment rur...</td>\n",
              "      <td>In Region älteren Menschen verehrt werden Zuma...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201286</th>\n",
              "      <td>Drei von zehn Südafrikanern sind jünger als 15...</td>\n",
              "      <td>Three in ten South Africans are younger than 1...</td>\n",
              "      <td>Three ten South Africans younger  meaning live...</td>\n",
              "      <td>Drei zehn Südafrikanern jünger  bedeutet Tag A...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201287</th>\n",
              "      <td>Irgendwie muss Zuma einen Weg finden, einersei...</td>\n",
              "      <td>Somehow Zuma must find a way to honor his own ...</td>\n",
              "      <td>Somehow Zuma must find way honor generations c...</td>\n",
              "      <td>Irgendwie Zuma Weg finden einerseits Engagemen...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192441 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e275b26-49b8-4964-9b17-d123b8203010')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e275b26-49b8-4964-9b17-d123b8203010 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e275b26-49b8-4964-9b17-d123b8203010');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-57af542b-43c9-4d6a-bef5-8a9c25b06f6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57af542b-43c9-4d6a-bef5-8a9c25b06f6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-57af542b-43c9-4d6a-bef5-8a9c25b06f6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_785dbf23-cfd4-4ba1-a5d5-a70b707d8ce2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dfappendclean')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_785dbf23-cfd4-4ba1-a5d5-a70b707d8ce2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dfappendclean');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snjjFtCc9-QW",
        "outputId": "7a55cf6f-4c9c-4c78-e960-ac7f4dee3639"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-313-b3f513c107bd>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_n=640\n",
        "total = int(1.20 * train_n)\n",
        "dfappendclean = dfappendclean.sample(total)\n",
        "dfappendclean_val = dfappendclean[:train_n]\n",
        "dfappendclean = dfappendclean[train_n:total]"
      ],
      "metadata": {
        "id": "jV5eOKElDTdC"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bos_string = 'bos '\n",
        "eos_string = ' eos'\n",
        "dfappendclean['english_clean'] = bos_string + dfappendclean['english_clean'].astype(str) + eos_string\n",
        "dfappendclean['german_clean'] = bos_string + dfappendclean['german_clean'].astype(str) + eos_string\n",
        "\n",
        "en_list =  dfappendclean['english_clean'].astype(str).tolist()\n",
        "ge_list =  dfappendclean['german_clean'].astype(str).tolist()\n",
        "en_list_val =  dfappendclean_val['english_clean'].astype(str).tolist()\n",
        "ge_list_val =  dfappendclean_val['german_clean'].astype(str).tolist()\n"
      ],
      "metadata": {
        "id": "h1DnFiSKDbVx"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(en_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9TfAz0cIEGMj",
        "outputId": "7640281a-64bc-4878-e5f6-f4ef33363339"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['bos America did indeed turn inward following fall Saigon neglect Afghanistan following Soviet withdrawal  led chaos Al Qaedas neartakeover country eos',\n",
              " 'bos It also calls government adopt within year legislation prohibit potentially harmful experiments great apes interests eos',\n",
              " 'bos Russias adherence WTOs legal framework begin make economic relations much stable predictable eos',\n",
              " 'bos Despite announced reforms unlikely significant exchangerate flexibility Chinas currency eos',\n",
              " 'bos The group brought together Gwyn Prins wellregarded expert security policy international relations heads LSEs Mackinder Programme Study Long Wave Events eos']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(ge_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "YSw7rMxREM7Y",
        "outputId": "301c5430-7d4e-44ec-a36d-4c818ac5fcd9"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['bos Tatsächlich zog Amerika Fall Saigons zurück Vernachlässigung Afghanistans sowjetischen Rückzug Jahr  führte Chaos beinahen Machtübernahme AlKaida Land eos',\n",
              " 'bos Sie verlangt außerdem Regierung innerhalb Jahres Gesetz erlassen potenziell schädliche Experimente Menschenaffen deren Interesse liegen untersagt eos',\n",
              " 'bos Wenn Russland rechtliche Regelwerks WHO hält dürften Wirtschaftsbeziehungen Land künftig stabiler vorhersehbarer gestalten eos',\n",
              " 'bos Trotz angekündigter Reformen unwahrscheinlich signifikanten Wechselkursflexibilität chinesischen Währung kommen wird eos',\n",
              " 'bos Die Expertengruppe traf Initiative Gwyn Prins renommierten Experten Sicherheitspolitik internationale Beziehungen Mackinder Programme LSE Erforschung langfristigen Ereignissen leitet eos']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en_tokenizer = Tokenizer();\n",
        "en_tokenizer.fit_on_texts(dfappendclean[\"english_clean\"])\n",
        "\n",
        "en_bos_index = en_tokenizer.word_index['bos']\n",
        "print(en_bos_index)\n",
        "en_eos_index = en_tokenizer.word_index['eos']\n",
        "print(en_eos_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPhqYJzf_7_q",
        "outputId": "ef6e2cd4-b01d-4283-ab35-fb69ee8b8cca"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ge_tokenizer = Tokenizer();\n",
        "ge_tokenizer.fit_on_texts(dfappendclean[\"german_clean\"])\n",
        "\n",
        "ge_bos_index = ge_tokenizer.word_index['bos']\n",
        "print(ge_bos_index)\n",
        "ge_eos_index = ge_tokenizer.word_index['eos']\n",
        "print(ge_eos_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg31udoEJc5Q",
        "outputId": "c07bb683-e4f5-4650-86f3-9658f154cd0a"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en = en_tokenizer.texts_to_sequences(en_list)     # Output is ragged.\n",
        "en = tf.keras.utils.pad_sequences(en, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge = ge_tokenizer.texts_to_sequences(ge_list)\n",
        "ge = tf.keras.utils.pad_sequences(ge, maxlen=MAX_TOKENS+1, padding='post')\n",
        "\n",
        "en_val = en_tokenizer.texts_to_sequences(en_list_val)     # Output is ragged.\n",
        "en_val = tf.keras.utils.pad_sequences(en_val, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge_val = ge_tokenizer.texts_to_sequences(ge_list_val)\n",
        "ge_val = tf.keras.utils.pad_sequences(ge_val, maxlen=MAX_TOKENS+1, padding='post')\n"
      ],
      "metadata": {
        "id": "q7WmtCIFGtMD"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((en, ge))\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((en_val, ge_val))"
      ],
      "metadata": {
        "id": "Gl2vCnjq21ZX"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "def prepare_batch(en, ge):\n",
        "\n",
        "    ge_inputs = ge[:, :-1]\n",
        "    ge_labels = ge[:, 1:]\n",
        "\n",
        "    return (en, ge_inputs), ge_labels\n",
        "\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "# Create training and validation set batches.\n",
        "dataset_batches = make_batches(dataset)\n",
        "dataset_batches_val = make_batches(dataset_val)"
      ],
      "metadata": {
        "id": "kPCJcclNXNnd"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (pt, en), en_labels in dataset_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49kSPXd5tQS",
        "outputId": "29b7026e-1456-413c-cecf-dabed56ab035"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "zl-TIYFgr9V1"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=128, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Zb5EHRCIsQH9"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "qdNlxpTmsX9j"
      },
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "UlwRgvGH9Rws"
      },
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "laK9VsbR9bhG"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ABwjtYoE9fUs"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "YcK04HCb9jFK"
      },
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2AugLcw09kna"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ],
      "metadata": {
        "id": "Bd7fjkrE9qSK"
      },
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ],
      "metadata": {
        "id": "YUxJrAa29vZA"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "metadata": {
        "id": "wjC6tbE09y-m"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Io4e9uNd93mO"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 128\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "7TXwHV0M97YX"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_size = len(en_tokenizer.word_index)+1;\n",
        "ge_vocab_size = len(ge_tokenizer.word_index)+1;\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size = en_vocab_size,\n",
        "    target_vocab_size = ge_vocab_size,\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "7dx2CYlLDGSB"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "fcaLfs1qPxBI"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "ANc7y6QmP18L"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "jFZama36QOd2"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "1ruovAGOQSwT"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(dataset_batches, epochs=1, validation_data=dataset_batches_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp4g1AOxQUHA",
        "outputId": "b275f827-3251-43e4-b95c-cf4ae194395d"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7c45bda2dd80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 57s 29s/step - loss: 7.2927 - masked_accuracy: 0.0000e+00 - val_loss: 7.3319 - val_masked_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c45a2027730>"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, en_tokenizer, ge_tokenizer, transformer):\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.ge_tokenizer = ge_tokenizer\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "\n",
        "    # assert isinstance(sentence, tf.Tensor)\n",
        "    # if len(sentence.shape) == 0:\n",
        "    #  sentence = sentence[tf.newaxis]\n",
        "    sentence = self.en_tokenizer.texts_to_sequences(sentence)\n",
        "    sentence = tf.keras.utils.pad_sequences(sentence, maxlen=MAX_TOKENS, padding='post')\n",
        "    encoder_input = sentence\n",
        "    start = tf.constant(ge_bos_index, dtype=tf.int64)[tf.newaxis]\n",
        "    end = ge_eos_index\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length-1):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # print(output[0].numpy())\n",
        "    text = ge_tokenizer.sequences_to_texts([output[0].numpy()])  # Shape: `()`.\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, attention_weights"
      ],
      "metadata": {
        "id": "90ryPhUFHzs4"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(en_tokenizer, ge_tokenizer, transformer)\n",
        "\n",
        "def print_translation(sentence, translated_text, ground_truth):\n",
        "  print(f'{\"Input\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {translated_text[0]}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "metadata": {
        "id": "W669EF07SlcC"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos The Chinese symbol form carries reasoning due use ideograms eos']\n",
        "ground_truth = 'bos Das chinesische Symbol Form verkörpert  aufgrund Verwendung Ideogrammen Chinesischen  Denkweise eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68LBNC3qJSEL",
        "outputId": "0c6ca822-516d-4bf5-cefa-e8b3bab89340"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos The Chinese symbol form carries reasoning due use ideograms eos']\n",
            "Prediction     : bos gewaltvideospielen potenzielle gewaltvideospielen potenzielle vergleich unterstützung platz finanzentwicklung mittels notwendig mittels unterstützung vergiftet unterstützung vergiftet leistungen vergiftet unterstützung vergiftet unterstützung vergiftet unterstützung vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung betrifft arbor vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung vergiftet vergiftet jährlich betrifft arbor jährlich arbor arbor arbor arafats arbor arafats arbor vergiftet opposition vergiftet ebene vergiftet opposition vergiftet ebene vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet liegt vergiftet liegt vergiftet vergiftet vergiftet unterstützung vergiftet unterstützung iran politischen vergiftet darüber vergiftet unterstützung iran unterstützung iran arbor vergiftet unterstützung vergiftet unterstützung iran investieren opposition opposition opposition opposition bereich gewaltvideospielen bereich gewaltvideospielen stationierung bereich kinder kinder bereich rationalen daraus strategischen wertpapiere völlig arbor vergiftet vergiftet vergiftet unterstützung vergiftet opposition chinas finanziellen vergiftet bos vergiftet unterstützung vergiftet heutigen bereich platz bereich\n",
            "Ground truth   : bos Das chinesische Symbol Form verkörpert  aufgrund Verwendung Ideogrammen Chinesischen  Denkweise eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos Energy carbon taxes produce less economic pain gain conventional taxes can eos']\n",
        "ground_truth = 'bos Energie COSteuern wirtschaftlicher Hinsicht weniger schmerzhaft dabei einträglicher herkömmliche Steuern eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jELXaPJ2ntQJ",
        "outputId": "ab785cf4-92cd-409d-d2bc-7b8d5e02ee68"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos Energy carbon taxes produce less economic pain gain conventional taxes can eos']\n",
            "Prediction     : bos gewaltvideospielen potenzielle gewaltvideospielen potenzielle vergleich unterstützung platz komponenten mittels notwendig mittels unterstützung vergiftet unterstützung erfüllen hinaus vergiftet unterstützung vergiftet unterstützung vergiftet unterstützung vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung betrifft arbor vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung vergiftet vergiftet jährlich betrifft arbor jährlich arbor arbor arbor jährlich arafats arbor staat hinaus vergiftet vergiftet vergiftet ebene vergiftet opposition vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet liegt vergiftet liegt vergiftet vergiftet unterstützung vergiftet unterstützung iran durchführt unterstützung vergiftet darüber vergiftet unterstützung iran unterstützung vergiftet unterstützung vergiftet unterstützung vergiftet unterstützung iran bereich iran bereich neuausrichtung bereich gewaltvideospielen bereich gewaltvideospielen stationierung bereich kinder bereich irrtümlicherweise sport vergiftet unterstützung schwierigkeiten gentile arbor vergiftet vergiftet vergiftet unterstützung vergiftet opposition chinas finanziellen vergiftet bos vergiftet unterstützung vergiftet heutigen bereich platz bereich\n",
            "Ground truth   : bos Energie COSteuern wirtschaftlicher Hinsicht weniger schmerzhaft dabei einträglicher herkömmliche Steuern eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos In India newborn health forms part national Reproductive Child Health Program eos']\n",
        "ground_truth = 'bos In Indien Gesundheit Neugeborener Teil Programms Fortpflanzungsmedizin Kindergesundheit eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoasrsFNn4ne",
        "outputId": "8b8e6f4d-5d31-4413-86cd-797aad470077"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos In India newborn health forms part national Reproductive Child Health Program eos']\n",
            "Prediction     : bos gewaltvideospielen potenzielle gewaltvideospielen potenzielle vergleich unterstützung platz komponenten mittels notwendig mittels unterstützung vergiftet unterstützung vergiftet leistungen vergiftet unterstützung vergiftet unterstützung vergiftet unterstützung vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung betrifft arbor vergiftet vergiftet vergiftet vergiftet vergiftet unterstützung vergiftet vergiftet jährlich betrifft arbor jährlich arbor arbor arbor jährlich arafats arbor staat hinaus vergiftet vergiftet ebene vergiftet opposition vergiftet ebene vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet vergiftet liegt vergiftet liegt vergiftet vergiftet unterstützung vergiftet unterstützung iran durchführt unterstützung vergiftet unterstützung iran unterstützung iran unterstützung vergiftet unterstützung vergiftet unterstützung vergiftet unterstützung iran bereich iran bereich neuausrichtung bereich gewaltvideospielen stationierung bereich gewaltvideospielen hoch opposition wertpapiere bereich rationalen daraus strategischen wertpapiere völlig arbor vergiftet vergiftet vergiftet unterstützung vergiftet opposition chinas finanziellen vergiftet zentrale vergiftet unterstützung vergiftet heutigen bereich platz bereich\n",
            "Ground truth   : bos In Indien Gesundheit Neugeborener Teil Programms Fortpflanzungsmedizin Kindergesundheit eos\n"
          ]
        }
      ]
    }
  ]
}