{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMjVfekVegD90K4ZDHlIBOd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narendra974/AIMLOPS_IISC/blob/main/NMT_TRANSFORMERS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcBLBDrOw_35",
        "outputId": "72bc83c3-7d48-4cab-f84e-971d51db2f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/DATASETS/ENG_DEU_DATA/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH5dpmIYxXjQ",
        "outputId": "7e8be075-6d8f-4dc9-e706-ce0343f76180"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycld2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8F6nrVRxqNk",
        "outputId": "2f203701-9c6f-491d-9596-60616fc8b549"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904028 sha256=aa28f740ab282cbc483a2a7b63ed59c6c4401162daf3289b79b7f1b6df91e9ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pycld2 as cld2\n",
        "import spacy\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import regex as re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences"
      ],
      "metadata": {
        "id": "EQfg9rSIx4rn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "!python -m spacy download de_core_news_sm\n",
        "gernlp = spacy.load('de_core_news_sm')\n",
        "engnlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdECDNilyFMe",
        "outputId": "03a2e856-56c1-4648-a644-3268a94835aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 12:10:26.848511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting de-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.11.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removestop(text,stopwords):\n",
        "  raw = text.split()\n",
        "  words = [word for word in raw if not word in stopwords]\n",
        "  cleanwords = ' '.join(words)\n",
        "  return cleanwords\n",
        "\n",
        "def tolower(text):\n",
        "  return text.lower()\n",
        "\n",
        "def removespecial(text):\n",
        "  te1 = re.sub(\"\\s+\",\" \",text)\n",
        "  te2 = re.sub('\\n', '', te1)\n",
        "  te3 = re.sub('\\r', '', te2)\n",
        "  te4 = re.sub(\"[0-9]\",\"\",te3)\n",
        "  te5 = re.sub(\"()@%^&*-_,/\\{}[?|$|.|!]\",\"\",te4)\n",
        "  te6 = re.sub(r\"[\\p{Cc}\\p{Cs}]+\",\"\",te5)\n",
        "  te7 = re.sub(r'[^\\w\\s]','', te6)\n",
        "  te8 = re.sub(\"[^a-zA-Z ]\",\"\",te7)\n",
        "  return te7\n",
        "\n",
        "def removeurl(text):\n",
        "  return re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    pattern = re.compile(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\")\n",
        "    text = re.sub(pattern,' ',text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "oIVXM3EIyp2r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basefolder =  \"/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/\"\n",
        "# germanfiles = [\"commoncrawl_de_en.txt\",\"europarl-v7_de_en.txt\",\"news-commentary-v9_de_en.txt\"]\n",
        "# engfiles = [\"commoncrawl_en_de.txt\",\"europarl-v7_en_de.txt\",\"news-commentary-v9_en_de.txt\"]\n",
        "germanfiles = [\"news-commentary-v9_de_en.txt\"]\n",
        "engfiles = [\"news-commentary-v9_en_de.txt\"]"
      ],
      "metadata": {
        "id": "l0kOP-4ZyV4w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_files(fileloc, language):\n",
        "  with open(fileloc,\"rb\") as f:\n",
        "    f_lines = f.readlines()\n",
        "  df = pd.DataFrame(f_lines)\n",
        "  dfc = df.set_axis([language],axis=1)\n",
        "  dfc[language] = dfc[language].str.decode(\"utf-8\")\n",
        "  return dfc"
      ],
      "metadata": {
        "id": "k5IkrZZHyvf2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend=pd.DataFrame()\n",
        "for efile in range(len(germanfiles)):\n",
        "  germanfilepath = basefolder+germanfiles[efile]\n",
        "  print(germanfilepath)\n",
        "  germandff = read_files(germanfilepath,\"german\")\n",
        "  engfilepath = basefolder+engfiles[efile]\n",
        "  engdff = read_files(engfilepath,\"english\")\n",
        "  print(germandff.shape)\n",
        "  print(engdff.shape)\n",
        "  dfconcat = pd.concat([germandff, engdff],axis=\"columns\")\n",
        "  dfappend=pd.concat([dfappend, dfconcat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1jGuFJMyzR8",
        "outputId": "60d4ecd5-1d5b-4bbb-bb91-51ee11322d77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DATASETS/ENG_DEU_DATA/news-commentary-v9_de_en.txt\n",
            "(201288, 1)\n",
            "(201288, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBH2yb4QzZGs",
        "outputId": "6d121e68-046b-42be-8a21-27e959e52eb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "german     0\n",
              "english    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxiAyjkzcR5",
        "outputId": "f55eff25-0340-45f4-c2bb-8fcc3cd85a58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "430"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend.drop_duplicates(subset=None, keep='first', inplace=True)\n",
        "dfappend.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l9j3y8mzkgi",
        "outputId": "40b06512-9978-4446-aa90-3cd5a168d99e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200858, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "german_stop_words = stopwords.words('german')\n",
        "english_stop_words = stopwords.words('english')\n",
        "\n",
        "dfappend['english_clean'] = dfappend['english'].apply(lambda x: removestop(x,english_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german'].apply(lambda x: removestop(x,german_stop_words))\n",
        "dfappend['german_clean'] = dfappend['german_clean'].apply(lambda x: removespecial(x))\n",
        "dfappend['english_clean'] = dfappend['english_clean'].apply(lambda x: removespecial(x))"
      ],
      "metadata": {
        "id": "GurWsMN50fwG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def langdet(x):\n",
        "  isReliable, textBytesFound, details = cld2.detect(x)\n",
        "  return(details[0][1])"
      ],
      "metadata": {
        "id": "KYehwk6C7IgV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappend['is_eng'] = dfappend['english_clean'].apply(lambda x: langdet(x))\n",
        "dfappend['is_ger'] = dfappend['german_clean'].apply(lambda x: langdet(x))"
      ],
      "metadata": {
        "id": "PQF2cq057NJ2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_ger\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "53KC07Ov72E5",
        "outputId": "8d71ecbe-c762-4504-fc70-61c0bb73d0b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "de     195236\n",
              "un       4267\n",
              "en        861\n",
              "nl         83\n",
              "lb         83\n",
              "ru         83\n",
              "nn         37\n",
              "da         35\n",
              "no         16\n",
              "na         13\n",
              "fy         12\n",
              "af         11\n",
              "la          7\n",
              "sv          7\n",
              "id          7\n",
              "pt          6\n",
              "ms          6\n",
              "fr          5\n",
              "tk          5\n",
              "war         5\n",
              "ie          5\n",
              "ro          5\n",
              "rm          5\n",
              "sk          4\n",
              "fi          4\n",
              "tr          3\n",
              "it          3\n",
              "pl          3\n",
              "eu          3\n",
              "es          3\n",
              "vo          3\n",
              "gv          2\n",
              "cs          2\n",
              "et          2\n",
              "tn          2\n",
              "ha          2\n",
              "lt          2\n",
              "gn          2\n",
              "hr          2\n",
              "rw          2\n",
              "ia          1\n",
              "mfe         1\n",
              "mt          1\n",
              "bi          1\n",
              "tl          1\n",
              "lv          1\n",
              "zzp         1\n",
              "ca          1\n",
              "az          1\n",
              "sco         1\n",
              "fo          1\n",
              "jw          1\n",
              "ts          1\n",
              "aa          1\n",
              "Name: is_ger, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappend[\"is_eng\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "6i9NdCLV8Pw6",
        "outputId": "f17f6cb0-e4aa-4574-db70-eb553db01936"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "en     196526\n",
              "un       4140\n",
              "sco        26\n",
              "ru         24\n",
              "da         20\n",
              "zh         17\n",
              "ca         10\n",
              "ms          7\n",
              "la          7\n",
              "id          5\n",
              "tr          5\n",
              "oc          5\n",
              "rw          5\n",
              "rm          4\n",
              "gn          3\n",
              "pt          3\n",
              "gv          3\n",
              "zzp         3\n",
              "es          3\n",
              "de          2\n",
              "co          2\n",
              "fr          2\n",
              "pl          2\n",
              "ro          2\n",
              "bs          2\n",
              "mfe         2\n",
              "nn          2\n",
              "uz          2\n",
              "ie          2\n",
              "ha          2\n",
              "hmn         1\n",
              "az          1\n",
              "lt          1\n",
              "mg          1\n",
              "af          1\n",
              "vo          1\n",
              "gl          1\n",
              "no          1\n",
              "fj          1\n",
              "sq          1\n",
              "sn          1\n",
              "ts          1\n",
              "sr          1\n",
              "ceb         1\n",
              "kha         1\n",
              "hu          1\n",
              "ga          1\n",
              "bi          1\n",
              "war         1\n",
              "tk          1\n",
              "Name: is_eng, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean = dfappend[(dfappend.is_eng == 'en') & (dfappend.is_ger =='de')]"
      ],
      "metadata": {
        "id": "nJM6MikS8amA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoGg225d8kea",
        "outputId": "6f939a73-3755-493c-93a2-c9b1a4e7e85a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192441, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dfappendclean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fPzF_1Qv8qSq",
        "outputId": "c9c6e441-241f-45a5-c8b6-29547f08b383"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   german  \\\n",
              "1       SAN FRANCISCO – Es war noch nie leicht, ein ra...   \n",
              "2       In letzter Zeit allerdings ist dies schwierige...   \n",
              "3       Erst letzten Dezember verfassten meine Kollege...   \n",
              "4                     Und es kam, wie es kommen musste.\\n   \n",
              "5       Seit der Veröffentlichung ihrer Artikel ist de...   \n",
              "...                                                   ...   \n",
              "201283  Das bleibt eine der größten Errungenschaften i...   \n",
              "201284  Gleichzeitig scheint sich Zumas revolutionäre ...   \n",
              "201285  In einer Region, wo die älteren Menschen sehr ...   \n",
              "201286  Drei von zehn Südafrikanern sind jünger als 15...   \n",
              "201287  Irgendwie muss Zuma einen Weg finden, einersei...   \n",
              "\n",
              "                                                  english  \\\n",
              "1       SAN FRANCISCO – It has never been easy to have...   \n",
              "2       Lately, with gold prices up more than 300% ove...   \n",
              "3       Just last December, fellow economists Martin F...   \n",
              "4                                 Wouldn’t you know it?\\n   \n",
              "5       Since their articles appeared, the price of go...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one of the greatest ...   \n",
              "201284  At the same time, Zuma’s revolutionary generat...   \n",
              "201285  In a region that reveres the elderly, Zuma’s a...   \n",
              "201286  Three in ten South Africans are younger than 1...   \n",
              "201287  Somehow Zuma must find a way to honor his own ...   \n",
              "\n",
              "                                            english_clean  \\\n",
              "1       SAN FRANCISCO  It never easy rational conversa...   \n",
              "2             Lately gold prices  last decade harder ever   \n",
              "3       Just last December fellow economists Martin Fe...   \n",
              "4                                         Wouldnt know it   \n",
              "5       Since articles appeared price gold moved still...   \n",
              "...                                                   ...   \n",
              "201283  Their achievement remains one greatest recent ...   \n",
              "201284  At time Zumas revolutionary generation still s...   \n",
              "201285  In region reveres elderly Zumas attachment rur...   \n",
              "201286  Three ten South Africans younger  meaning live...   \n",
              "201287  Somehow Zuma must find way honor generations c...   \n",
              "\n",
              "                                             german_clean is_eng is_ger  \n",
              "1       SAN FRANCISCO  Es nie leicht rationales Gesprä...     en     de  \n",
              "2       In letzter Zeit allerdings schwieriger je Gold...     en     de  \n",
              "3       Erst letzten Dezember verfassten Kollegen Mart...     en     de  \n",
              "4                                   Und kam kommen musste     en     de  \n",
              "5       Seit Veröffentlichung Artikel Goldpreis gestiegen     en     de  \n",
              "...                                                   ...    ...    ...  \n",
              "201283  Das bleibt größten Errungenschaften jüngeren G...     en     de  \n",
              "201284  Gleichzeitig scheint Zumas revolutionäre Gener...     en     de  \n",
              "201285  In Region älteren Menschen verehrt werden Zuma...     en     de  \n",
              "201286  Drei zehn Südafrikanern jünger  bedeutet Tag A...     en     de  \n",
              "201287  Irgendwie Zuma Weg finden einerseits Engagemen...     en     de  \n",
              "\n",
              "[192441 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c55c80ae-238e-4439-ba87-6d87c083e05e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>german</th>\n",
              "      <th>english</th>\n",
              "      <th>english_clean</th>\n",
              "      <th>german_clean</th>\n",
              "      <th>is_eng</th>\n",
              "      <th>is_ger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAN FRANCISCO – Es war noch nie leicht, ein ra...</td>\n",
              "      <td>SAN FRANCISCO – It has never been easy to have...</td>\n",
              "      <td>SAN FRANCISCO  It never easy rational conversa...</td>\n",
              "      <td>SAN FRANCISCO  Es nie leicht rationales Gesprä...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In letzter Zeit allerdings ist dies schwierige...</td>\n",
              "      <td>Lately, with gold prices up more than 300% ove...</td>\n",
              "      <td>Lately gold prices  last decade harder ever</td>\n",
              "      <td>In letzter Zeit allerdings schwieriger je Gold...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Erst letzten Dezember verfassten meine Kollege...</td>\n",
              "      <td>Just last December, fellow economists Martin F...</td>\n",
              "      <td>Just last December fellow economists Martin Fe...</td>\n",
              "      <td>Erst letzten Dezember verfassten Kollegen Mart...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Und es kam, wie es kommen musste.\\n</td>\n",
              "      <td>Wouldn’t you know it?\\n</td>\n",
              "      <td>Wouldnt know it</td>\n",
              "      <td>Und kam kommen musste</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Seit der Veröffentlichung ihrer Artikel ist de...</td>\n",
              "      <td>Since their articles appeared, the price of go...</td>\n",
              "      <td>Since articles appeared price gold moved still...</td>\n",
              "      <td>Seit Veröffentlichung Artikel Goldpreis gestiegen</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201283</th>\n",
              "      <td>Das bleibt eine der größten Errungenschaften i...</td>\n",
              "      <td>Their achievement remains one of the greatest ...</td>\n",
              "      <td>Their achievement remains one greatest recent ...</td>\n",
              "      <td>Das bleibt größten Errungenschaften jüngeren G...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201284</th>\n",
              "      <td>Gleichzeitig scheint sich Zumas revolutionäre ...</td>\n",
              "      <td>At the same time, Zuma’s revolutionary generat...</td>\n",
              "      <td>At time Zumas revolutionary generation still s...</td>\n",
              "      <td>Gleichzeitig scheint Zumas revolutionäre Gener...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201285</th>\n",
              "      <td>In einer Region, wo die älteren Menschen sehr ...</td>\n",
              "      <td>In a region that reveres the elderly, Zuma’s a...</td>\n",
              "      <td>In region reveres elderly Zumas attachment rur...</td>\n",
              "      <td>In Region älteren Menschen verehrt werden Zuma...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201286</th>\n",
              "      <td>Drei von zehn Südafrikanern sind jünger als 15...</td>\n",
              "      <td>Three in ten South Africans are younger than 1...</td>\n",
              "      <td>Three ten South Africans younger  meaning live...</td>\n",
              "      <td>Drei zehn Südafrikanern jünger  bedeutet Tag A...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201287</th>\n",
              "      <td>Irgendwie muss Zuma einen Weg finden, einersei...</td>\n",
              "      <td>Somehow Zuma must find a way to honor his own ...</td>\n",
              "      <td>Somehow Zuma must find way honor generations c...</td>\n",
              "      <td>Irgendwie Zuma Weg finden einerseits Engagemen...</td>\n",
              "      <td>en</td>\n",
              "      <td>de</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>192441 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c55c80ae-238e-4439-ba87-6d87c083e05e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c55c80ae-238e-4439-ba87-6d87c083e05e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c55c80ae-238e-4439-ba87-6d87c083e05e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-917cbcc4-08e0-4bdf-9b7f-44703f09dd5f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-917cbcc4-08e0-4bdf-9b7f-44703f09dd5f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-917cbcc4-08e0-4bdf-9b7f-44703f09dd5f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d1219646-a9f8-4eb1-a578-74cedc561002\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dfappendclean')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d1219646-a9f8-4eb1-a578-74cedc561002 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dfappendclean');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snjjFtCc9-QW",
        "outputId": "43b2dd70-c753-4169-edf1-f3e3b779e685"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-b3f513c107bd>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dfappendclean[\"engcount\"]=dfappendclean['english_clean'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_n=10000\n",
        "total = int(1.20 * train_n)\n",
        "dfappendclean = dfappendclean.sample(total)\n",
        "dfappendclean_val = dfappendclean[train_n:total]\n",
        "dfappendclean = dfappendclean[:train_n]"
      ],
      "metadata": {
        "id": "jV5eOKElDTdC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bos_string = 'bos '\n",
        "eos_string = ' eos'\n",
        "dfappendclean['english_clean'] = bos_string + dfappendclean['english_clean'].astype(str) + eos_string\n",
        "dfappendclean['german_clean'] = bos_string + dfappendclean['german_clean'].astype(str) + eos_string\n",
        "\n",
        "en_list =  dfappendclean['english_clean'].astype(str).tolist()\n",
        "ge_list =  dfappendclean['german_clean'].astype(str).tolist()\n",
        "en_list_val =  dfappendclean_val['english_clean'].astype(str).tolist()\n",
        "ge_list_val =  dfappendclean_val['german_clean'].astype(str).tolist()\n"
      ],
      "metadata": {
        "id": "h1DnFiSKDbVx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(en_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9TfAz0cIEGMj",
        "outputId": "d8984eed-3cfd-49e3-8045-36904c55cffc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['bos But whatever level nominal interest rates monetarypolicy stance established way often poorly transmitted economy particularly times acute crisis eos',\n",
              " 'bos That makes frightening ordinary criminals eos',\n",
              " 'bos The international communitys old approach prioritize stability democracy pursue IsraeliArab peace completely separate diplomatic track eos',\n",
              " 'bos This could story Romanian revolution  years ago eos',\n",
              " 'bos In Europe crisis management mechanisms must put place manage deeply integrated nature  Europes banking assets held crossborder banking groups eos']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(ge_list[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "YSw7rMxREM7Y",
        "outputId": "cd7725b1-0c76-4200-dab4-9d5b7f6fcd78"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['bos Aber unabhängig Nominalverzinsung festgelegte geldpolitische Kurs oft geringem Maße Wirtschaft übertragen besonders Zeiten akuter Krisen eos',\n",
              " 'bos Das macht Terroristen Furcht erregender gewöhnliche Kriminelle eos',\n",
              " 'bos Der alte Ansatz internationalen Gemeinschaft bestand darin Stabilität Demokratie stellen israelischarabischen Frieden völlig diplomatischen Schiene verfolgen eos',\n",
              " 'bos Dies Geschichte rumänischen Revolution  Jahren sein eos',\n",
              " 'bos Es müssen Europa Mechanismen Krisenmanagement eingerichtet werden hochintegrierten Charakter europäischen Kapitalmärkte Rechnung tragen  Gesamtbilanzsumme Europa tätigen Kreditinstitute grenzübergreifenden Bankkonzernen gehalten eos']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en_tokenizer = Tokenizer();\n",
        "en_tokenizer.fit_on_texts(dfappendclean[\"english_clean\"])\n",
        "\n",
        "en_bos_index = en_tokenizer.word_index['bos']\n",
        "print(en_bos_index)\n",
        "en_eos_index = en_tokenizer.word_index['eos']\n",
        "print(en_eos_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPhqYJzf_7_q",
        "outputId": "88293bd0-fc51-4ef0-e991-a58c312a35be"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ge_tokenizer = Tokenizer();\n",
        "ge_tokenizer.fit_on_texts(dfappendclean[\"german_clean\"])\n",
        "\n",
        "ge_bos_index = ge_tokenizer.word_index['bos']\n",
        "print(ge_bos_index)\n",
        "ge_eos_index = ge_tokenizer.word_index['eos']\n",
        "print(ge_eos_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg31udoEJc5Q",
        "outputId": "e8ff5c81-e36f-4bf5-870c-ca07dcdcd426"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "en = en_tokenizer.texts_to_sequences(en_list)     # Output is ragged.\n",
        "en = tf.keras.utils.pad_sequences(en, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge = ge_tokenizer.texts_to_sequences(ge_list)\n",
        "ge = tf.keras.utils.pad_sequences(ge, maxlen=MAX_TOKENS+1, padding='post')\n",
        "\n",
        "en_val = en_tokenizer.texts_to_sequences(en_list_val)     # Output is ragged.\n",
        "en_val = tf.keras.utils.pad_sequences(en_val, maxlen=MAX_TOKENS, padding='post')\n",
        "\n",
        "ge_val = ge_tokenizer.texts_to_sequences(ge_list_val)\n",
        "ge_val = tf.keras.utils.pad_sequences(ge_val, maxlen=MAX_TOKENS+1, padding='post')\n"
      ],
      "metadata": {
        "id": "q7WmtCIFGtMD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((en, ge))\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices((en_val, ge_val))"
      ],
      "metadata": {
        "id": "Gl2vCnjq21ZX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64\n",
        "def prepare_batch(en, ge):\n",
        "\n",
        "    ge_inputs = ge[:, :-1]\n",
        "    ge_labels = ge[:, 1:]\n",
        "\n",
        "    return (en, ge_inputs), ge_labels\n",
        "\n",
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "# Create training and validation set batches.\n",
        "dataset_batches = make_batches(dataset)\n",
        "dataset_batches_val = make_batches(dataset_val)"
      ],
      "metadata": {
        "id": "kPCJcclNXNnd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (pt, en), en_labels in dataset_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i49kSPXd5tQS",
        "outputId": "656e9e79-10d0-4efb-de8f-543831c4e59a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 128)\n",
            "(64, 128)\n",
            "(64, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "zl-TIYFgr9V1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=128, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "Zb5EHRCIsQH9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "metadata": {
        "id": "qdNlxpTmsX9j"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "UlwRgvGH9Rws"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "laK9VsbR9bhG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ABwjtYoE9fUs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "YcK04HCb9jFK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2AugLcw09kna"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ],
      "metadata": {
        "id": "Bd7fjkrE9qSK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ],
      "metadata": {
        "id": "YUxJrAa29vZA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "metadata": {
        "id": "wjC6tbE09y-m"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "metadata": {
        "id": "Io4e9uNd93mO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 3\n",
        "d_model = 128\n",
        "dff = 128\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "7TXwHV0M97YX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_vocab_size = len(en_tokenizer.word_index)+1;\n",
        "ge_vocab_size = len(ge_tokenizer.word_index)+1;\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size = en_vocab_size,\n",
        "    target_vocab_size = ge_vocab_size,\n",
        "    dropout_rate=dropout_rate)"
      ],
      "metadata": {
        "id": "7dx2CYlLDGSB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "fcaLfs1qPxBI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "ANc7y6QmP18L"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "jFZama36QOd2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "metadata": {
        "id": "1ruovAGOQSwT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(dataset_batches, epochs=30, validation_data=dataset_batches_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp4g1AOxQUHA",
        "outputId": "c127a8fc-75a6-4e90-d6ec-fccdd3858aca"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "157/157 [==============================] - 691s 4s/step - loss: 10.1454 - masked_accuracy: 0.0482 - val_loss: 9.9714 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "157/157 [==============================] - 672s 4s/step - loss: 9.5872 - masked_accuracy: 0.0690 - val_loss: 9.2828 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "157/157 [==============================] - 654s 4s/step - loss: 8.8872 - masked_accuracy: 0.0691 - val_loss: 8.8726 - val_masked_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "157/157 [==============================] - 651s 4s/step - loss: 8.5449 - masked_accuracy: 0.0701 - val_loss: 8.8495 - val_masked_accuracy: 1.3140e-04\n",
            "Epoch 5/30\n",
            "157/157 [==============================] - 651s 4s/step - loss: 8.3398 - masked_accuracy: 0.0785 - val_loss: 8.7831 - val_masked_accuracy: 0.0013\n",
            "Epoch 6/30\n",
            "157/157 [==============================] - 654s 4s/step - loss: 8.1418 - masked_accuracy: 0.0804 - val_loss: 8.7936 - val_masked_accuracy: 0.0050\n",
            "Epoch 7/30\n",
            "157/157 [==============================] - 652s 4s/step - loss: 7.9294 - masked_accuracy: 0.0843 - val_loss: 8.7091 - val_masked_accuracy: 0.0083\n",
            "Epoch 8/30\n",
            "157/157 [==============================] - 653s 4s/step - loss: 7.6682 - masked_accuracy: 0.0945 - val_loss: 8.6865 - val_masked_accuracy: 0.0186\n",
            "Epoch 9/30\n",
            "157/157 [==============================] - 651s 4s/step - loss: 7.3539 - masked_accuracy: 0.1086 - val_loss: 8.6542 - val_masked_accuracy: 0.0258\n",
            "Epoch 10/30\n",
            "157/157 [==============================] - 649s 4s/step - loss: 6.9851 - masked_accuracy: 0.1274 - val_loss: 8.4729 - val_masked_accuracy: 0.0408\n",
            "Epoch 11/30\n",
            "157/157 [==============================] - 649s 4s/step - loss: 6.5637 - masked_accuracy: 0.1551 - val_loss: 8.3297 - val_masked_accuracy: 0.0524\n",
            "Epoch 12/30\n",
            "157/157 [==============================] - 653s 4s/step - loss: 6.0930 - masked_accuracy: 0.1890 - val_loss: 8.3536 - val_masked_accuracy: 0.0638\n",
            "Epoch 13/30\n",
            "157/157 [==============================] - 662s 4s/step - loss: 5.5752 - masked_accuracy: 0.2311 - val_loss: 8.3599 - val_masked_accuracy: 0.0659\n",
            "Epoch 14/30\n",
            "157/157 [==============================] - 663s 4s/step - loss: 5.0124 - masked_accuracy: 0.2850 - val_loss: 8.3451 - val_masked_accuracy: 0.0766\n",
            "Epoch 15/30\n",
            "157/157 [==============================] - 665s 4s/step - loss: 4.4237 - masked_accuracy: 0.3528 - val_loss: 8.4443 - val_masked_accuracy: 0.0798\n",
            "Epoch 16/30\n",
            "157/157 [==============================] - 663s 4s/step - loss: 3.8192 - masked_accuracy: 0.4236 - val_loss: 8.6343 - val_masked_accuracy: 0.0818\n",
            "Epoch 17/30\n",
            "157/157 [==============================] - 663s 4s/step - loss: 3.2276 - masked_accuracy: 0.4910 - val_loss: 8.7436 - val_masked_accuracy: 0.0845\n",
            "Epoch 18/30\n",
            "157/157 [==============================] - 663s 4s/step - loss: 2.6689 - masked_accuracy: 0.5596 - val_loss: 9.0757 - val_masked_accuracy: 0.0834\n",
            "Epoch 19/30\n",
            "157/157 [==============================] - 669s 4s/step - loss: 2.1583 - masked_accuracy: 0.6278 - val_loss: 9.3147 - val_masked_accuracy: 0.0768\n",
            "Epoch 20/30\n",
            "157/157 [==============================] - 664s 4s/step - loss: 1.7128 - masked_accuracy: 0.6913 - val_loss: 9.6135 - val_masked_accuracy: 0.0745\n",
            "Epoch 21/30\n",
            "157/157 [==============================] - 665s 4s/step - loss: 1.3396 - masked_accuracy: 0.7522 - val_loss: 9.9464 - val_masked_accuracy: 0.0705\n",
            "Epoch 22/30\n",
            "157/157 [==============================] - 665s 4s/step - loss: 1.0446 - masked_accuracy: 0.7979 - val_loss: 10.3178 - val_masked_accuracy: 0.0638\n",
            "Epoch 23/30\n",
            "157/157 [==============================] - 668s 4s/step - loss: 0.8330 - masked_accuracy: 0.8314 - val_loss: 10.7348 - val_masked_accuracy: 0.0572\n",
            "Epoch 24/30\n",
            "157/157 [==============================] - 667s 4s/step - loss: 0.6913 - masked_accuracy: 0.8525 - val_loss: 11.3045 - val_masked_accuracy: 0.0455\n",
            "Epoch 25/30\n",
            "157/157 [==============================] - 672s 4s/step - loss: 0.6011 - masked_accuracy: 0.8658 - val_loss: 13.8741 - val_masked_accuracy: 0.0110\n",
            "Epoch 26/30\n",
            "157/157 [==============================] - 667s 4s/step - loss: 0.5360 - masked_accuracy: 0.8773 - val_loss: 16.1586 - val_masked_accuracy: 0.0036\n",
            "Epoch 27/30\n",
            "157/157 [==============================] - 667s 4s/step - loss: 0.4649 - masked_accuracy: 0.8909 - val_loss: 17.9688 - val_masked_accuracy: 0.0017\n",
            "Epoch 28/30\n",
            "157/157 [==============================] - 671s 4s/step - loss: 0.4039 - masked_accuracy: 0.9037 - val_loss: 16.9671 - val_masked_accuracy: 0.0039\n",
            "Epoch 29/30\n",
            "157/157 [==============================] - 675s 4s/step - loss: 0.3516 - masked_accuracy: 0.9151 - val_loss: 20.0371 - val_masked_accuracy: 4.0572e-04\n",
            "Epoch 30/30\n",
            "157/157 [==============================] - 675s 4s/step - loss: 0.3074 - masked_accuracy: 0.9256 - val_loss: 16.4264 - val_masked_accuracy: 0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d195f56dc60>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icHZ9q6D7WFY",
        "outputId": "293f866f-72ee-4c0f-f6bf-2c58baa6222f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Encoder)           multiple                  3965056   \n",
            "                                                                 \n",
            " decoder (Decoder)           multiple                  6934784   \n",
            "                                                                 \n",
            " dense_12 (Dense)            multiple                  3697140   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,596,980\n",
            "Trainable params: 14,596,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, en_tokenizer, ge_tokenizer, transformer):\n",
        "    self.en_tokenizer = en_tokenizer\n",
        "    self.ge_tokenizer = ge_tokenizer\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "\n",
        "    # assert isinstance(sentence, tf.Tensor)\n",
        "    # if len(sentence.shape) == 0:\n",
        "    #  sentence = sentence[tf.newaxis]\n",
        "    sentence = self.en_tokenizer.texts_to_sequences(sentence)\n",
        "    sentence = tf.keras.utils.pad_sequences(sentence, maxlen=MAX_TOKENS, padding='post')\n",
        "    encoder_input = sentence\n",
        "    start = tf.constant(ge_bos_index, dtype=tf.int64)[tf.newaxis]\n",
        "    end = ge_eos_index\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length-1):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # print(output[0].numpy())\n",
        "    text = ge_tokenizer.sequences_to_texts([output[0].numpy()])  # Shape: `()`.\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, attention_weights"
      ],
      "metadata": {
        "id": "90ryPhUFHzs4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(en_tokenizer, ge_tokenizer, transformer)\n",
        "\n",
        "def print_translation(sentence, translated_text, ground_truth):\n",
        "  print(f'{\"Input\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {translated_text[0]}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "metadata": {
        "id": "W669EF07SlcC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos The Chinese symbol form carries reasoning due use ideograms eos']\n",
        "ground_truth = 'bos Das chinesische Symbol Form verkörpert  aufgrund Verwendung Ideogrammen Chinesischen  Denkweise eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68LBNC3qJSEL",
        "outputId": "418bcbbf-881c-43a0-f05e-df48d551e3a2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos The Chinese symbol form carries reasoning due use ideograms eos']\n",
            "Prediction     : bos das chinesen aufnehmen bevor zweites liberia schaden zuzufügen eos\n",
            "Ground truth   : bos Das chinesische Symbol Form verkörpert  aufgrund Verwendung Ideogrammen Chinesischen  Denkweise eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos Energy carbon taxes produce less economic pain gain conventional taxes can eos']\n",
        "ground_truth = 'bos Energie COSteuern wirtschaftlicher Hinsicht weniger schmerzhaft dabei einträglicher herkömmliche Steuern eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jELXaPJ2ntQJ",
        "outputId": "f9df86d6-838f-4261-e925-976e243b21b5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos Energy carbon taxes produce less economic pain gain conventional taxes can eos']\n",
            "Prediction     : bos die energiecharta bereits weniger stärke erwarten gewinnen teilzuhaben stammaktionären zufließen steuern erhöhen eos\n",
            "Ground truth   : bos Energie COSteuern wirtschaftlicher Hinsicht weniger schmerzhaft dabei einträglicher herkömmliche Steuern eos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['bos In India newborn health forms part national Reproductive Child Health Program eos']\n",
        "ground_truth = 'bos In Indien Gesundheit Neugeborener Teil Programms Fortpflanzungsmedizin Kindergesundheit eos'\n",
        "translated_text, attention_weights = translator(sentence)\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoasrsFNn4ne",
        "outputId": "ed0d5fc6-86d9-4b8b-f6c2-5762fb564b8b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input          : ['bos In India newborn health forms part national Reproductive Child Health Program eos']\n",
            "Prediction     : bos in indien gesundheit bemerkt erst bilden beitritt krisenzeiten zugeführt werden eos\n",
            "Ground truth   : bos In Indien Gesundheit Neugeborener Teil Programms Fortpflanzungsmedizin Kindergesundheit eos\n"
          ]
        }
      ]
    }
  ]
}